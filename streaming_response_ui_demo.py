"""
æµå¼å“åº”UIæ¼”ç¤º
å±•ç¤ºå¦‚ä½•åœ¨å‰ç«¯ç•Œé¢ä¸­å¯ç”¨æµå¼å“åº”å’Œé¦–å­—å“åº”æ—¶é—´åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import time
from ui_components import StreamingResponseMetricsComponents, ResultDisplayComponents
from advanced_llm_analyzer import AdvancedLLMAnalyzer

def main():
    st.set_page_config(
        page_title="æµå¼å“åº”UIæ¼”ç¤º",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    st.title("ğŸš€ æµå¼å“åº”å’Œé¦–å­—å“åº”æ—¶é—´UIæ¼”ç¤º")
    
    st.markdown("""
    æ­¤æ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•åœ¨å‰ç«¯ç•Œé¢ä¸­å¯ç”¨æµå¼å“åº”åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - âš¡ é¦–å­—å“åº”æ—¶é—´æµ‹é‡
    - â±ï¸ æ€»å“åº”æ—¶é—´è®°å½•
    - ğŸ”„ APIé‡è¯•æ¬¡æ•°ç»Ÿè®¡
    - ğŸ“Š æ€§èƒ½æŒ‡æ ‡å¯è§†åŒ–
    - ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®
    """)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    @st.cache_data
    def create_sample_data():
        """åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼ŒåŒ…å«æµå¼å“åº”æŒ‡æ ‡"""
        data = {
            'åœºæ™¯': [f'æµ‹è¯•åœºæ™¯{i+1}' for i in range(10)],
            'å‚è€ƒç­”æ¡ˆ': [f'å‚è€ƒç­”æ¡ˆ{i+1}' for i in range(10)],
            'ç”Ÿæˆç­”æ¡ˆ1': [f'ç”Ÿæˆç­”æ¡ˆ{i+1}' for i in range(10)],
            'llm_first_token_response_time': [
                0.234, 0.567, 0.123, 0.789, 0.345,
                0.678, 0.234, 0.567, 0.123, 0.789
            ],
            'llm_total_response_time': [
                2.345, 3.678, 1.234, 4.567, 2.890,
                3.456, 2.345, 3.678, 1.234, 4.567
            ],
            'llm_api_attempt': [1, 1, 2, 1, 1, 3, 1, 1, 2, 1],
            'llm_overall_score': [85, 92, 78, 88, 90, 76, 89, 91, 84, 87]
        }
        return pd.DataFrame(data)
    
    # æ˜¾ç¤ºåŠŸèƒ½è¯´æ˜
    st.header("ğŸ”§ åŠŸèƒ½é…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âœ… å½“å‰å®ç°çš„åŠŸèƒ½")
        st.markdown("""
        - **ğŸš€ æµå¼å“åº”é€‰é¡¹** - åœ¨LLMåˆ†æè®¾ç½®ä¸­å¯å¯ç”¨
        - **âš¡ é¦–å­—å“åº”æ—¶é—´** - æµ‹é‡ä»è¯·æ±‚åˆ°ç¬¬ä¸€ä¸ªå­—ç¬¦çš„æ—¶é—´
        - **â±ï¸ æ€»å“åº”æ—¶é—´** - å®Œæ•´è¯·æ±‚å“åº”æ—¶é—´
        - **ğŸ”„ APIé‡è¯•æ¬¡æ•°** - è®°å½•è¯·æ±‚é‡è¯•æƒ…å†µ
        - **ğŸ“Š æ€§èƒ½æŒ‡æ ‡é¢æ¿** - å¯è§†åŒ–å±•ç¤ºæ€§èƒ½æ•°æ®
        - **ğŸ’¡ æ™ºèƒ½å»ºè®®** - åŸºäºæ€§èƒ½æ•°æ®çš„ä¼˜åŒ–å»ºè®®
        """)
    
    with col2:
        st.subheader("ğŸ¯ ä½¿ç”¨æ–¹æ³•")
        st.markdown("""
        1. åœ¨**åˆ†æé…ç½®**ä¸­å¯ç”¨ "ğŸ§  LLMæ·±åº¦åˆ†æ"
        2. å‹¾é€‰ "ğŸš€ å¯ç”¨æµå¼å“åº”" é€‰é¡¹
        3. å¼€å§‹åˆ†æï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è®°å½•æ—¶é—´æŒ‡æ ‡
        4. åœ¨ç»“æœé¡µé¢æŸ¥çœ‹ "ğŸš€ è¯¦ç»†æµå¼å“åº”æŒ‡æ ‡"
        5. æ ¹æ®æ€§èƒ½å»ºè®®ä¼˜åŒ–é…ç½®
        """)
    
    # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
    st.header("ğŸ“Š ç¤ºä¾‹æ•°æ®å±•ç¤º")
    
    sample_df = create_sample_data()
    
    # ä½¿ç”¨æ–°çš„UIç»„ä»¶æ˜¾ç¤ºåˆ†ææ‘˜è¦
    ResultDisplayComponents.show_analysis_summary(sample_df)
    
    # æ˜¾ç¤ºåŸå§‹æ•°æ®
    st.subheader("ğŸ“‹ åŸå§‹æ•°æ®")
    st.dataframe(sample_df)
    
    # é…ç½®è¯´æ˜
    st.header("âš™ï¸ é…ç½®è¯´æ˜")
    
    st.markdown("""
    ### åœ¨ `app.py` ä¸­çš„é…ç½®ï¼š
    
    ```python
    # LLMåˆ†æé€‰é¡¹
    enable_llm_analysis = st.checkbox("ğŸ§  å¯ç”¨LLMæ·±åº¦åˆ†æ", value=False)
    
    if enable_llm_analysis:
        # æµå¼å“åº”é€‰é¡¹
        enable_streaming = st.checkbox(
            "ğŸš€ å¯ç”¨æµå¼å“åº”",
            value=False,
            help="å¯ç”¨æµå¼å“åº”å¯ä»¥æµ‹é‡é¦–å­—å“åº”æ—¶é—´ï¼Œæ›´å¥½åœ°è¯„ä¼°APIæ€§èƒ½"
        )
        
        if enable_streaming:
            st.info("ğŸ“Š å°†è®°å½•é¦–å­—å“åº”æ—¶é—´å’Œæ€»å“åº”æ—¶é—´")
    ```
    
    ### åœ¨åˆ†æå™¨ä¸­çš„è°ƒç”¨ï¼š
    
    ```python
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨æµå¼å“åº”
    use_streaming = st.session_state.get('enable_streaming', False)
    
    # è°ƒç”¨åˆ†æå™¨
    result_df = analyzer.batch_analyze_dataframe(
        df, 'å‚è€ƒç­”æ¡ˆ', 'ç”Ÿæˆç­”æ¡ˆ1', 'comprehensive',
        use_streaming=use_streaming  # ä¼ é€’æµå¼å“åº”å‚æ•°
    )
    ```
    
    ### ç»“æœæ•°æ®æ ¼å¼ï¼š
    
    å¯ç”¨æµå¼å“åº”åï¼Œç»“æœDataFrameä¼šåŒ…å«ä»¥ä¸‹é¢å¤–åˆ—ï¼š
    - `llm_first_token_response_time`: é¦–å­—å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    - `llm_total_response_time`: æ€»å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    - `llm_api_attempt`: APIé‡è¯•æ¬¡æ•°
    """)
    
    # æ€§èƒ½åŸºå‡†
    st.header("ğŸ¯ æ€§èƒ½åŸºå‡†")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "ğŸš€ é¦–å­—å“åº”æ—¶é—´",
            "< 1.0s",
            delta="ä¼˜ç§€",
            delta_color="normal"
        )
        st.caption("ä»è¯·æ±‚å¼€å§‹åˆ°æ¥æ”¶ç¬¬ä¸€ä¸ªå­—ç¬¦")
    
    with col2:
        st.metric(
            "â±ï¸ æ€»å“åº”æ—¶é—´",
            "< 10.0s",
            delta="æ»¡æ„",
            delta_color="normal"
        )
        st.caption("å®Œæ•´è¯·æ±‚å“åº”æ—¶é—´")
    
    with col3:
        st.metric(
            "ğŸ”„ APIé‡è¯•æ¬¡æ•°",
            "= 1",
            delta="ç†æƒ³",
            delta_color="normal"
        )
        st.caption("é¦–æ¬¡æˆåŠŸç‡ > 95%")
    
    # ä½¿ç”¨è¯´æ˜
    st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
    
    with st.expander("ğŸ” è¯¦ç»†ä½¿ç”¨æ­¥éª¤"):
        st.markdown("""
        1. **å¯ç”¨åŠŸèƒ½**ï¼š
           - åœ¨åˆ†æé…ç½®ä¸­å¯ç”¨ "ğŸ§  LLMæ·±åº¦åˆ†æ"
           - å‹¾é€‰ "ğŸš€ å¯ç”¨æµå¼å“åº”" é€‰é¡¹
        
        2. **å¼€å§‹åˆ†æ**ï¼š
           - ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨æµå¼å“åº”æ–¹å¼
           - è®°å½•æ¯ä¸ªè¯·æ±‚çš„é¦–å­—å“åº”æ—¶é—´å’Œæ€»å“åº”æ—¶é—´
        
        3. **æŸ¥çœ‹ç»“æœ**ï¼š
           - åœ¨åˆ†ææ‘˜è¦ä¸­æŸ¥çœ‹å¹³å‡æ—¶é—´æŒ‡æ ‡
           - ç‚¹å‡» "ğŸš€ è¯¦ç»†æµå¼å“åº”æŒ‡æ ‡" æŸ¥çœ‹è¯¦ç»†åˆ†æ
        
        4. **æ€§èƒ½ä¼˜åŒ–**ï¼š
           - æ ¹æ®æ€§èƒ½å»ºè®®è°ƒæ•´é…ç½®
           - ç›‘æ§é¦–å­—å“åº”æ—¶é—´å’Œé‡è¯•æ¬¡æ•°
        
        5. **æ•°æ®å¯¼å‡º**ï¼š
           - æ‰€æœ‰æ—¶é—´æŒ‡æ ‡éƒ½ä¼šä¿å­˜åœ¨ç»“æœæ–‡ä»¶ä¸­
           - å¯ç”¨äºè¿›ä¸€æ­¥çš„æ€§èƒ½åˆ†æ
        """)
    
    # æŠ€æœ¯ç»†èŠ‚
    with st.expander("ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚"):
        st.markdown("""
        ### æµå¼å“åº”å®ç°ï¼š
        
        ```python
        def send_evaluation_request_streaming(self, prompt: str) -> Dict:
            request_start_time = time.time()
            
            # å‘é€æµå¼è¯·æ±‚
            response = requests.post(url, json=data, stream=True)
            
            first_byte_time = None
            full_content = ""
            
            # é€å—è¯»å–å“åº”
            for chunk in response.iter_content(chunk_size=1):
                if chunk:
                    if first_byte_time is None:
                        first_byte_time = time.time()
                        first_token_response_time = first_byte_time - request_start_time
                    full_content += chunk
            
            total_response_time = time.time() - request_start_time
            
            return {
                'content': full_content,
                'first_token_response_time': first_token_response_time,
                'total_response_time': total_response_time
            }
        ```
        
        ### UIç»„ä»¶é›†æˆï¼š
        
        ```python
        class StreamingResponseMetricsComponents:
            @staticmethod
            def show_streaming_metrics(df):
                # æ˜¾ç¤ºé¦–å­—å“åº”æ—¶é—´åˆ†å¸ƒ
                # æ˜¾ç¤ºæ€»å“åº”æ—¶é—´åˆ†æ
                # æ˜¾ç¤ºAPIé‡è¯•ç»Ÿè®¡
                # æ˜¾ç¤ºæ€§èƒ½ä¼˜åŒ–å»ºè®®
        ```
        """)

if __name__ == "__main__":
    main() 