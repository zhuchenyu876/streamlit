#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import os
import glob
from typing import Dict, List, Any, Optional
import time
from file_manager import file_manager

class AdvancedLLMDashboard:
    """
    å¢å¼ºç‰ˆLLMåˆ†æDashboardï¼Œå±•ç¤ºå¤šç»´åº¦åˆ†æç»“æœ
    """
    
    def __init__(self):
        self.color_scheme = {
            'primary': '#1f77b4',
            'secondary': '#ff7f0e', 
            'success': '#2ca02c',
            'warning': '#d62728',
            'info': '#17becf',
            'light': '#bcbd22',
            'dark': '#8c564b'
        }
        self.analyzer = None
        self.evaluation_dimensions = {
            'factual_accuracy': 'äº‹å®å‡†ç¡®æ€§',
            'semantic_consistency': 'è¯­ä¹‰ä¸€è‡´æ€§', 
            'business_logic_compliance': 'ä¸šåŠ¡é€»è¾‘ç¬¦åˆæ€§',
            'response_completeness': 'å›ç­”å®Œæ•´æ€§',
            'information_relevance': 'ä¿¡æ¯ç›¸å…³æ€§',
            'language_quality': 'è¯­è¨€è´¨é‡',
            'user_intent_fulfillment': 'ç”¨æˆ·æ„å›¾æ»¡è¶³åº¦',
            'technical_accuracy': 'æŠ€æœ¯å‡†ç¡®æ€§',
            'context_understanding': 'ä¸Šä¸‹æ–‡ç†è§£',
            'professional_tone': 'ä¸“ä¸šç¨‹åº¦'
        }
        
        self.tire_business_dimensions = {
            'tire_spec_accuracy': 'è½®èƒè§„æ ¼å‡†ç¡®æ€§',
            'price_accuracy': 'ä»·æ ¼å‡†ç¡®æ€§',
            'stock_accuracy': 'åº“å­˜å‡†ç¡®æ€§',
            'brand_consistency': 'å“ç‰Œä¸€è‡´æ€§',
            'service_info_accuracy': 'æœåŠ¡ä¿¡æ¯å‡†ç¡®æ€§',
            'sales_process_compliance': 'é”€å”®æµç¨‹ç¬¦åˆæ€§'
        }

    def show_advanced_llm_dashboard(self):
        """æ˜¾ç¤ºå¢å¼ºç‰ˆLLMåˆ†æDashboard"""
        
        # æ¨¡å¼é€‰æ‹©åŒºåŸŸ
        self._show_mode_selector()
        
        # æ•°æ®åŠ è½½å’Œåˆ†æ
        self._load_and_analyze_data()
    
    def _load_and_analyze_data(self):
        """åŠ è½½å’Œåˆ†ææ•°æ®"""
        # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ•°æ®åŠ è½½æ–¹å¼
        mode = st.session_state.get('llm_mode', 'demo')
        
        if mode == 'demo':
            # æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            self._show_demo_analysis()
        elif mode == 'from_first_step':
            # ä»ç¬¬ä¸€æ­¥ç»“æœè¿›è¡Œåˆ†æ
            self._show_first_step_analysis()
        else:
            # APIæ¨¡å¼ï¼šåŠ è½½çœŸå®åˆ†ææ•°æ®
            self._show_real_analysis()
    
    def _show_demo_analysis(self):
        """æ˜¾ç¤ºæ¼”ç¤ºæ¨¡å¼åˆ†æ"""
        st.markdown("### ğŸ“Š æ¼”ç¤ºæ¨¡å¼åˆ†æç»“æœ")
        
        # ç”Ÿæˆæ¼”ç¤ºæ•°æ®
        demo_data = self._generate_demo_data()
        
        if demo_data is not None:
            # æ˜¾ç¤ºåˆ†æç»“æœ
            self._show_analysis_overview(demo_data)
            
            # åˆ›å»ºtabs
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ“Š ç»¼åˆè¯„ä¼°", "ğŸ› ä¸šåŠ¡åˆ†æ", "ğŸ¤– Agentå¯¹æ¯”", 
                "ğŸ“ˆ å¯¹æ¯”ä¼ ç»Ÿæ–¹æ³•", "ğŸ“‹ è¯¦ç»†æ•°æ®"
            ])
            
            with tab1:
                self._show_comprehensive_analysis(demo_data)
            
            with tab2:
                self._show_business_analysis(demo_data)
            
            with tab3:
                self._show_agent_comparison(demo_data)
            
            with tab4:
                self._show_method_comparison(demo_data)
            
            with tab5:
                self._show_detailed_data(demo_data)
    
    def _show_real_analysis(self):
        """æ˜¾ç¤ºçœŸå®APIæ¨¡å¼åˆ†æ"""
        st.markdown("### ğŸš€ çœŸå®APIæ¨¡å¼åˆ†æ")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨é€‰æ‹©æ–‡ä»¶
        auto_select_file = st.session_state.get('auto_select_file', None)
        if auto_select_file:
            # è‡ªåŠ¨é€‰æ‹©åˆšä¿å­˜çš„æ–‡ä»¶
            selected_file = auto_select_file
            st.info(f"ğŸ“Š æ­£åœ¨æ˜¾ç¤ºåˆšå®Œæˆçš„åˆ†æç»“æœï¼š{os.path.basename(selected_file)}")
            # æ¸…é™¤è‡ªåŠ¨é€‰æ‹©æ ‡å¿—
            st.session_state.pop('auto_select_file', None)
        else:
            # æ–‡ä»¶é€‰æ‹©å™¨
            data_files = self._get_available_analysis_files()
            
            if not data_files:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¢å¼ºLLMåˆ†æç»“æœæ–‡ä»¶")
                st.info("ğŸ’¡ è¯·å…ˆè¿è¡Œå¢å¼ºLLMåˆ†ææ¥ç”Ÿæˆæ•°æ®")
                
                # æä¾›è¿è¡Œåˆ†æçš„é€‰é¡¹
                if st.button("ğŸš€ è¿è¡Œå¢å¼ºLLMåˆ†æ"):
                    st.info("è¯·å‰å¾€'Analysis'æ ‡ç­¾é¡µè¿è¡Œå¢å¼ºLLMåˆ†æ")
                return
            
            selected_file = st.selectbox(
                "é€‰æ‹©åˆ†æç»“æœæ–‡ä»¶",
                data_files,
                help="é€‰æ‹©è¦æŸ¥çœ‹çš„å¢å¼ºLLMåˆ†æç»“æœæ–‡ä»¶"
            )
        
        if selected_file:
            df = self._load_analysis_data(selected_file)
            
            if df is not None and not df.empty:
                # æ˜¾ç¤ºåˆ†æç»“æœ
                self._show_analysis_overview(df)
                
                # åˆ›å»ºtabs
                tab1, tab2, tab3, tab4, tab5 = st.tabs([
                    "ğŸ“Š ç»¼åˆè¯„ä¼°", "ğŸ› ä¸šåŠ¡åˆ†æ", "ğŸ¤– Agentå¯¹æ¯”", 
                    "ğŸ“ˆ å¯¹æ¯”ä¼ ç»Ÿæ–¹æ³•", "ğŸ“‹ è¯¦ç»†æ•°æ®"
                ])
                
                with tab1:
                    self._show_comprehensive_analysis(df)
                
                with tab2:
                    self._show_business_analysis(df)
                
                with tab3:
                    self._show_agent_comparison(df)
                
                with tab4:
                    self._show_method_comparison(df)
                
                with tab5:
                    self._show_detailed_data(df)
            else:
                st.error("âŒ æ— æ³•åŠ è½½åˆ†ææ•°æ®")
    
    def _show_first_step_analysis(self):
        """æ˜¾ç¤ºä»ç¬¬ä¸€æ­¥ç»“æœè¿›è¡Œçš„åˆ†æ"""
        st.markdown("### ğŸš€ ä»ç¬¬ä¸€æ­¥ç»“æœè¿›è¡Œå¢å¼ºLLMåˆ†æ")
        
        # è·å–ç¬¬ä¸€æ­¥åˆ†æç»“æœæ–‡ä»¶
        first_step_files = self._get_first_step_analysis_files()
        
        if not first_step_files:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¬ä¸€æ­¥åˆ†æç»“æœæ–‡ä»¶")
            st.info("ğŸ’¡ è¯·å…ˆåœ¨'Analysis'æ ‡ç­¾é¡µè¿è¡ŒåŸºç¡€åˆ†ææ¥ç”Ÿæˆæ•°æ®")
            return
        
        # æ–‡ä»¶é€‰æ‹©å™¨
        st.markdown("### ğŸ“ é€‰æ‹©ç¬¬ä¸€æ­¥åˆ†æç»“æœ")
        
        selected_file = st.selectbox(
            "é€‰æ‹©è¦è¿›è¡ŒLLMå¢å¼ºåˆ†æçš„åŸºç¡€ç»“æœæ–‡ä»¶",
            first_step_files,
            help="é€‰æ‹©ä¸€ä¸ªåŸºç¡€åˆ†æç»“æœæ–‡ä»¶è¿›è¡ŒLLMå¢å¼ºåˆ†æ"
        )
        
        if selected_file:
            # åŠ è½½å¹¶é¢„è§ˆæ•°æ®
            df = self._load_analysis_data(selected_file)
            
            if df is not None and not df.empty:
                # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
                st.markdown("### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ğŸ“ˆ æ€»æ ·æœ¬æ•°", len(df))
                
                with col2:
                    if 'åœºæ™¯' in df.columns:
                        scenario_count = int(df['åœºæ™¯'].nunique())
                        st.metric("ğŸ¯ åœºæ™¯æ•°é‡", scenario_count)
                    else:
                        st.metric("ğŸ¯ åœºæ™¯æ•°é‡", "N/A")
                
                with col3:
                    if 'åŒ…å«é”™è¯¯' in df.columns:
                        error_rate = (df['åŒ…å«é”™è¯¯'] == 'æ˜¯').sum() / len(df) * 100
                        st.metric("âŒ é”™è¯¯ç‡", f"{error_rate:.1f}%")
                    else:
                        st.metric("âŒ é”™è¯¯ç‡", "N/A")
                
                with col4:
                    if 'è¯­ä¹‰ç¨³å®šæ€§' in df.columns:
                        try:
                            if 'è¯­ä¹‰ç¨³å®šæ€§' in df.columns:
                                stability_values = df['è¯­ä¹‰ç¨³å®šæ€§'].dropna()
                                if len(stability_values) > 0:
                                    avg_stability = float(stability_values.mean())
                                    st.metric("ğŸ”„ å¹³å‡ç¨³å®šæ€§", f"{avg_stability:.1f}%")
                                else:
                                    st.metric("ğŸ”„ å¹³å‡ç¨³å®šæ€§", "N/A")
                            else:
                                st.metric("ğŸ”„ å¹³å‡ç¨³å®šæ€§", "N/A")
                        except:
                            st.metric("ğŸ”„ å¹³å‡ç¨³å®šæ€§", "N/A")
                    else:
                        st.metric("ğŸ”„ å¹³å‡ç¨³å®šæ€§", "N/A")
                
                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®é¢„è§ˆ
                with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ (å‰5è¡Œ)", expanded=False):
                    display_cols = ['åœºæ™¯', 'æµ‹è¯•æ•°æ®', 'å‚è€ƒç­”æ¡ˆ', 'ç”Ÿæˆç­”æ¡ˆ1', 'è¯­ä¹‰ç¨³å®šæ€§', 'å®Œæ•´åº¦', 'ç›¸å…³åº¦']
                    available_cols = [col for col in display_cols if col in df.columns]
                    if available_cols:
                        st.dataframe(df[available_cols].head(), use_container_width=True)
                    else:
                        st.dataframe(df.head(), use_container_width=True)
                
                # è¿è¡ŒLLMå¢å¼ºåˆ†æ
                st.markdown("---")
                self._show_llm_analysis_interface(df)
            else:
                st.error("âŒ æ— æ³•åŠ è½½åˆ†ææ•°æ®")
    
    def _get_first_step_analysis_files(self) -> List[str]:
        """è·å–ç¬¬ä¸€æ­¥åˆ†æç»“æœæ–‡ä»¶"""
        import os
        import glob
        
        # æŸ¥æ‰¾åŸºç¡€åˆ†æç»“æœæ–‡ä»¶ï¼ˆä¸åŒ…å«advanced_llmå’Œjson_metricsçš„æ–‡ä»¶ï¼‰
        pattern = "qa_analysis_results/qa_analysis_results_*.csv"
        all_files = glob.glob(pattern)
        
        first_step_files = []
        for file in all_files:
            # æ’é™¤å·²ç»è¿›è¡Œè¿‡LLMåˆ†æçš„æ–‡ä»¶
            if 'advanced_llm' not in file and 'json_metrics' not in file:
                try:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰åŸºç¡€åˆ†æç»“æœ
                    df = pd.read_csv(file, nrows=1)  # åªè¯»å–ç¬¬ä¸€è¡Œæ£€æŸ¥åˆ—å
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºç¡€åˆ†æçš„å…³é”®åˆ—
                    if any(col in df.columns for col in ['ç”Ÿæˆç­”æ¡ˆ1', 'å‚è€ƒç­”æ¡ˆ', 'æµ‹è¯•æ•°æ®']):
                        first_step_files.append(file)
                except Exception:
                    continue
        
        return sorted(first_step_files, reverse=True)
    
    def _show_llm_analysis_interface(self, df: pd.DataFrame):
        """æ˜¾ç¤ºLLMåˆ†æç•Œé¢"""
        st.markdown("### ğŸ§  LLMå¢å¼ºåˆ†æé…ç½®")
        
        # æ™ºèƒ½æ ·æœ¬é€‰æ‹©
        col1, col2 = st.columns(2)
        
        with col1:
            sample_options = {
                "quick_10": {
                    "name": "ğŸš€ å¿«é€Ÿæµ‹è¯• (10ä¸ªæ ·æœ¬)", 
                    "count": 10, 
                    "time": "2-3åˆ†é’Ÿ",
                    "analysis_type": "business_only",
                    "description": "ä¸šåŠ¡åˆ†æï¼Œå¿«é€ŸéªŒè¯"
                },
                "moderate_50": {
                    "name": "âš¡ ä¸­ç­‰åˆ†æ (50ä¸ªæ ·æœ¬)", 
                    "count": 50, 
                    "time": "10-15åˆ†é’Ÿ",
                    "analysis_type": "business_only",
                    "description": "ä¸šåŠ¡åˆ†æï¼Œå¹³è¡¡æ•ˆæœä¸é€Ÿåº¦"
                },
                "comprehensive_100": {
                    "name": "ğŸ“Š æ·±åº¦åˆ†æ (100ä¸ªæ ·æœ¬)", 
                    "count": 100, 
                    "time": "20-30åˆ†é’Ÿ",
                    "analysis_type": "business_only",
                    "description": "ä¸šåŠ¡åˆ†æï¼Œæ·±åº¦è¯„ä¼°"
                },
                "full_analysis": {
                    "name": "ğŸ”¬ å®Œæ•´åˆ†æ (å…¨éƒ¨æ ·æœ¬)", 
                    "count": len(df), 
                    "time": f"{len(df)*3*3//60}-{len(df)*3*5//60}åˆ†é’Ÿ",
                    "analysis_type": "comprehensive",
                    "description": "å…¨é¢åˆ†æï¼Œæœ€å®Œæ•´è¯„ä¼°"
                }
            }
            
            # æ ¹æ®æ•°æ®é‡è°ƒæ•´æ¨è
            if len(df) <= 20:
                recommended = "comprehensive_100"
            elif len(df) <= 100:
                recommended = "moderate_50"
            else:
                recommended = "quick_10"
            
            sample_choice = st.radio(
                "é€‰æ‹©åˆ†ææ–¹æ¡ˆ",
                options=list(sample_options.keys()),
                format_func=lambda x: f"{sample_options[x]['name']} - {sample_options[x]['description']}",
                index=list(sample_options.keys()).index(recommended),
                help="æ™ºèƒ½æ–¹æ¡ˆä¼šè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„åˆ†æç±»å‹å’Œæ ·æœ¬æ•°é‡"
            )
            
            selected_count = sample_options[sample_choice]["count"]
            analysis_type = sample_options[sample_choice]["analysis_type"]  # è‡ªåŠ¨è®¾ç½®åˆ†æç±»å‹
            
        with col2:
            # æ˜¾ç¤ºæ—¶é—´é¢„ä¼°å’Œè¯´æ˜
            if analysis_type == "comprehensive":
                api_calls_per_sample = 3
                time_per_call = 4
            else:
                api_calls_per_sample = 1
                time_per_call = 3
            
            total_api_calls = selected_count * api_calls_per_sample
            estimated_seconds = total_api_calls * time_per_call
            
            st.info(f"""
            **åˆ†ææ–¹æ¡ˆè¯¦æƒ…ï¼š**
            - æ ·æœ¬æ•°ï¼š{selected_count}
            - åˆ†æç±»å‹ï¼š{analysis_type}
            - APIè°ƒç”¨ï¼š{total_api_calls} æ¬¡
            - é¢„è®¡æ—¶é—´ï¼š{estimated_seconds//60}åˆ†{estimated_seconds%60}ç§’
            """)
        
        # å¦‚æœé€‰æ‹©æ ·æœ¬æ•°å°äºæ€»æ•°ï¼Œè¿›è¡Œé‡‡æ ·
        if selected_count < len(df):
            df_to_analyze = df.sample(n=selected_count, random_state=42).reset_index(drop=True)
            st.info(f"ğŸ“Š å·²ä» {len(df)} ä¸ªæ ·æœ¬ä¸­éšæœºé€‰æ‹© {selected_count} ä¸ªè¿›è¡Œåˆ†æ")
        else:
            df_to_analyze = df
            
        # APIé…ç½®æ£€æŸ¥
        if not self._check_api_configuration():
            st.error("âŒ è¯·å…ˆé…ç½®LLM APIå‚æ•°")
            return
        
        # ç¬¬ä¸€æ­¥ï¼šæ˜¾ç¤ºåˆ†æå‡†å¤‡æŒ‰é’®
        if st.button("ğŸš€ å‡†å¤‡LLMå¢å¼ºåˆ†æ", type="primary", use_container_width=True):
            st.session_state['llm_analysis_prepared'] = True
            st.session_state['llm_analysis_data'] = {
                'df': df_to_analyze,
                'selected_count': selected_count,
                'analysis_type': analysis_type,
                'estimated_seconds': estimated_seconds,
                'total_api_calls': total_api_calls,
                'sample_choice': sample_choice
            }
            st.rerun()
        
        # ç¬¬äºŒæ­¥ï¼šå¦‚æœå·²ç»å‡†å¤‡å¥½åˆ†æï¼Œæ˜¾ç¤ºç¡®è®¤ç•Œé¢å’ŒçœŸæ­£çš„å¼€å§‹æŒ‰é’®
        if st.session_state.get('llm_analysis_prepared', False):
            analysis_data = st.session_state.get('llm_analysis_data', {})
            
            # æ˜¾ç¤ºåˆ†æé…ç½®ç¡®è®¤
            st.success("âœ… åˆ†æé…ç½®å·²å‡†å¤‡å®Œæˆ")
            
            # æ˜¾ç¤ºåˆ†æé…ç½®è¯¦æƒ…
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"""
                **ğŸ“Š åˆ†æé…ç½®è¯¦æƒ…ï¼š**
                - æ ·æœ¬æ•°é‡ï¼š{analysis_data.get('selected_count', 0)} ä¸ª
                - åˆ†æç±»å‹ï¼š{analysis_data.get('analysis_type', 'unknown')}
                - APIè°ƒç”¨ï¼š{analysis_data.get('total_api_calls', 0)} æ¬¡
                - é¢„è®¡æ—¶é—´ï¼š{analysis_data.get('estimated_seconds', 0)//60} åˆ†é’Ÿ
                """)
            
            with col2:
                st.warning(f"""
                **âš ï¸ æ³¨æ„äº‹é¡¹ï¼š**
                - åˆ†æè¿‡ç¨‹ä¸­è¯·å‹¿å…³é—­é¡µé¢
                - ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
                - åˆ†æè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
                - å»ºè®®åœ¨ç©ºé—²æ—¶æ®µè¿›è¡Œåˆ†æ
                """)
            
            # æä¾›å–æ¶ˆå’Œç¡®è®¤æŒ‰é’®
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("âŒ å–æ¶ˆåˆ†æ", type="secondary", use_container_width=True):
                    st.session_state.pop('llm_analysis_prepared', None)
                    st.session_state.pop('llm_analysis_data', None)
                    st.success("âœ… åˆ†æå·²å–æ¶ˆ")
                    st.rerun()
            
            with col2:
                if st.button("ğŸ”¥ çœŸæ­£å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
                    # å‡†å¤‡æ•°æ®
                    df_to_analyze = analysis_data['df']
                    selected_count = analysis_data['selected_count']
                    analysis_type = analysis_data['analysis_type']
                    estimated_seconds = analysis_data['estimated_seconds']
                    total_api_calls = analysis_data['total_api_calls']
                    
                    # åˆ›å»ºåˆ†æå™¨é…ç½®
                    config = self._get_llm_config()
                    
                    # æ¸…é™¤å‡†å¤‡çŠ¶æ€
                    st.session_state.pop('llm_analysis_prepared', None)
                    st.session_state.pop('llm_analysis_data', None)
                    
                    # ç›´æ¥å¼€å§‹åˆ†æ
                    with st.spinner("ğŸš€ æ­£åœ¨å¯åŠ¨LLMå¢å¼ºåˆ†æ..."):
                        self._run_llm_analysis_direct(df_to_analyze, analysis_type, config)
    
    def _run_llm_analysis_direct(self, df: pd.DataFrame, analysis_type: str, config: Dict):
        """ç›´æ¥è¿è¡ŒLLMåˆ†æ"""
        try:
            # é¢„ä¼°æ—¶é—´è®¡ç®—
            sample_count = len(df)
            if analysis_type == "comprehensive":
                api_calls = sample_count * 3
                estimated_time = api_calls * 4
            elif analysis_type == "business_only":
                api_calls = sample_count * 1
                estimated_time = api_calls * 3
            elif analysis_type == "comparison_only":
                api_calls = sample_count * 1
                estimated_time = api_calls * 3
            else:
                api_calls = sample_count * 3
                estimated_time = api_calls * 4
            
            # æ˜¾ç¤ºåˆ†æå¼€å§‹ä¿¡æ¯
            st.info(f"""
            ğŸš€ LLMå¢å¼ºåˆ†æå·²å¯åŠ¨
            - æ ·æœ¬æ•°é‡ï¼š{sample_count} ä¸ª
            - åˆ†æç±»å‹ï¼š{analysis_type}
            - APIè°ƒç”¨æ¬¡æ•°ï¼š{api_calls} æ¬¡
            - é¢„è®¡æ—¶é—´ï¼š{estimated_time//60} åˆ†é’Ÿ {estimated_time%60} ç§’
            """)
            
            # å¯¼å…¥åˆ†æå™¨
            from advanced_llm_analyzer import AdvancedLLMAnalyzer
            
            # ä¼˜åŒ–é…ç½®
            optimized_config = {
                **config,
                'timeout': 60,
                'max_retries': 3,
                'retry_delay': 2,
                'url': 'https://agents.dyna.ai/openapi/v1/conversation/dialog/',
                'robot_key': 'AcZ%2FQzIk8m6UV0uNkXi3HO1pJPI%3D',
                'robot_token': 'MTc1MjEzMDE5Njc3NQp2SE5aZU92SFUvT1JwSVMvaFN3S3Jza1BlU1U9',
                'username': 'edison.chu@dyna.ai'
            }
            
            # åˆ›å»ºåˆ†æå™¨
            st.success("âœ… æ­£åœ¨åˆå§‹åŒ–åˆ†æå™¨...")
            analyzer = AdvancedLLMAnalyzer(optimized_config)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆ›å»ºå®æ—¶ç»“æœæ˜¾ç¤ºåŒºåŸŸ
            st.markdown("### ğŸ“Š å®æ—¶åˆ†æç»“æœ")
            realtime_results_container = st.empty()
            
            # ç”¨äºå­˜å‚¨å®æ—¶ç»“æœ
            if 'realtime_results' not in st.session_state:
                st.session_state.realtime_results = []
            
            start_time = time.time()
            
            def update_progress(current, total, current_result=None):
                # æ›´æ–°å®æ—¶ç»“æœ
                if current_result is not None:
                    st.session_state.realtime_results.append(current_result)
                
                # ç¡®ä¿è¿›åº¦å€¼åœ¨0-1ä¹‹é—´
                if total > 0:
                    progress = min(max(current / total, 0.0), 1.0)
                else:
                    progress = 0.0
                
                try:
                    progress_bar.progress(progress)
                except Exception as e:
                    st.error(f"è¿›åº¦æ¡æ›´æ–°é”™è¯¯: {str(e)}")
                    return
                
                elapsed_time = time.time() - start_time
                
                if current > 0:
                    avg_time_per_item = elapsed_time / current
                    remaining_items = max(total - current, 0)
                    estimated_remaining = avg_time_per_item * remaining_items
                    
                    status_text.info(f"""
                    ğŸ§  æ­£åœ¨è¿›è¡ŒLLMæ·±åº¦åˆ†æ...
                    - è¿›åº¦ï¼š{current}/{total} æ ·æœ¬ ({progress:.1%})
                    - å·²ç”¨æ—¶ï¼š{elapsed_time//60:.0f}åˆ†{elapsed_time%60:.0f}ç§’
                    - é¢„è®¡å‰©ä½™ï¼š{estimated_remaining//60:.0f}åˆ†{estimated_remaining%60:.0f}ç§’
                    - æ¯ä¸ªæ ·æœ¬å¹³å‡è€—æ—¶{avg_time_per_item:.1f}ç§’
                    """)
                else:
                    status_text.info(f"""
                    ğŸš€ å¼€å§‹åˆ†æç¬¬ä¸€ä¸ªæ ·æœ¬...
                    - æ€»è®¡éœ€è¦åˆ†æï¼š{total} ä¸ªæ ·æœ¬
                    - é¢„è®¡APIè°ƒç”¨ï¼š{api_calls} æ¬¡
                    """)
                
                # æ›´æ–°å®æ—¶ç»“æœæ˜¾ç¤º
                if st.session_state.realtime_results:
                    self._update_realtime_results(realtime_results_container, st.session_state.realtime_results, current, total)
            
            # æ¸…ç©ºä¹‹å‰çš„å®æ—¶ç»“æœ
            st.session_state.realtime_results = []
            
            # å¼€å§‹åˆ†æ
            st.info("ğŸ”„ å¼€å§‹æ•°æ®åˆ†æ...")
            
            try:
                # åˆ›å»ºæ”¯æŒå®æ—¶ç»“æœçš„å›è°ƒå‡½æ•°
                def realtime_progress_callback(current, total, current_row=None):
                    # å¦‚æœæœ‰å½“å‰è¡Œæ•°æ®ï¼Œæ·»åŠ åˆ°å®æ—¶ç»“æœä¸­
                    current_result = None
                    if current_row is not None:
                        current_result = current_row.to_dict()
                    
                    # è°ƒç”¨æ›´æ–°è¿›åº¦çš„å‡½æ•°
                    update_progress(current, total, current_result)
                
                result_df = analyzer.batch_analyze_dataframe(
                    df, 'å‚è€ƒç­”æ¡ˆ', 'ç”Ÿæˆç­”æ¡ˆ1', analysis_type,
                    progress_callback=realtime_progress_callback
                )
                
                # è®¡ç®—æ€»ç”¨æ—¶
                total_time = time.time() - start_time
                
                # ä¿å­˜ç»“æœ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_path = f'./qa_analysis_results/qa_analysis_results_{timestamp}_advanced_llm.csv'
                output_path = file_manager.save_csv(result_df, output_path, index=False, encoding='utf-8-sig')
                
                # æ¸…ç†è¿›åº¦æ˜¾ç¤º
                progress_bar.empty()
                status_text.empty()
                realtime_results_container.empty()
                
                # æ¸…ç†å®æ—¶ç»“æœ
                if 'realtime_results' in st.session_state:
                    del st.session_state['realtime_results']
                
                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                st.success(f"""
                âœ… LLMå¢å¼ºåˆ†æå®Œæˆï¼
                - åˆ†ææ ·æœ¬ï¼š{len(df)} ä¸ª
                - APIè°ƒç”¨ï¼š{api_calls} æ¬¡
                - æ€»ç”¨æ—¶ï¼š{total_time//60:.0f}åˆ†{total_time%60:.0f}ç§’
                - ä¿å­˜ä½ç½®ï¼š{output_path}
                """)
                
                st.balloons()
                
                # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                st.markdown("### ğŸ“Š åˆ†æç»“æœé¢„è§ˆ")
                
                # æ˜¾ç¤ºLLMåˆ†æåˆ—
                llm_cols = [col for col in result_df.columns if col.startswith('llm_')]
                if llm_cols:
                    st.dataframe(result_df[llm_cols[:8]], use_container_width=True)
                
                # æä¾›ä¸‹è½½
                csv_data = file_manager.get_download_data(output_path)
                if csv_data:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†æç»“æœ",
                        data=csv_data,
                        file_name=f"advanced_llm_analysis_{timestamp}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                
                # æä¾›æŸ¥çœ‹è¯¦ç»†ç»“æœçš„é€‰é¡¹
                if st.button("ğŸ“Š æŸ¥çœ‹è¯¦ç»†åˆ†æç»“æœ", use_container_width=True):
                    st.session_state['llm_mode'] = 'api'
                    st.session_state['auto_select_file'] = output_path
                    st.rerun()
                
            except Exception as analysis_error:
                # æ¸…ç†è¿›åº¦æ˜¾ç¤º
                progress_bar.empty()
                status_text.empty()
                realtime_results_container.empty()
                
                # æ¸…ç†å®æ—¶ç»“æœ
                if 'realtime_results' in st.session_state:
                    del st.session_state['realtime_results']
                
                # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                st.error("âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
                
                error_msg = str(analysis_error)
                if "504" in error_msg or "Gateway Time-out" in error_msg:
                    st.error("""
                    ğŸš¨ **APIè¶…æ—¶é”™è¯¯**
                    - é—®é¢˜: APIæœåŠ¡å™¨å“åº”è¶…æ—¶
                    - å»ºè®®: å‡å°‘æ ·æœ¬æ•°é‡æˆ–ç¨åå†è¯•
                    """)
                elif "timeout" in error_msg.lower():
                    st.error("""
                    â° **è¯·æ±‚è¶…æ—¶**
                    - é—®é¢˜: è¯·æ±‚å¤„ç†æ—¶é—´è¿‡é•¿
                    - å»ºè®®: é€‰æ‹©è¾ƒå°‘çš„æ ·æœ¬æ•°é‡
                    """)
                else:
                    st.error(f"**é”™è¯¯è¯¦æƒ…**: {error_msg}")
                
                # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
                with st.expander("ğŸ” å®Œæ•´é”™è¯¯ä¿¡æ¯"):
                    st.code(error_msg)
            
        except Exception as e:
            st.error(f"âŒ åˆ†æåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.error("è¯·æ£€æŸ¥APIé…ç½®æ˜¯å¦æ­£ç¡®")
            
            # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                st.code(str(e))
    
    def _update_realtime_results(self, container, results, current, total):
        """æ›´æ–°å®æ—¶ç»“æœæ˜¾ç¤º"""
        try:
            with container.container():
                # æ˜¾ç¤ºå½“å‰è¿›åº¦
                st.info(f"å·²å®Œæˆ {current}/{total} ä¸ªæ ·æœ¬ ({current/total:.1%})")
                
                if results:
                    # åˆ›å»ºç»“æœDataFrame
                    import pandas as pd
                    df_results = pd.DataFrame(results)
                    
                    # æ˜¾ç¤ºæœ€æ–°çš„5ä¸ªç»“æœ
                    st.markdown("#### ğŸ“Š æœ€æ–°åˆ†æç»“æœ (æœ€è¿‘5ä¸ª)")
                    
                    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
                    display_columns = []
                    if 'æµ‹è¯•æ•°æ®' in df_results.columns:
                        display_columns.append('æµ‹è¯•æ•°æ®')
                    if 'å‚è€ƒç­”æ¡ˆ' in df_results.columns:
                        display_columns.append('å‚è€ƒç­”æ¡ˆ')
                    if 'ç”Ÿæˆç­”æ¡ˆ1' in df_results.columns:
                        display_columns.append('ç”Ÿæˆç­”æ¡ˆ1')
                    
                    # æ·»åŠ LLMåˆ†æç»“æœåˆ—
                    llm_columns = [col for col in df_results.columns if col.startswith('llm_') and col.endswith('_score')]
                    display_columns.extend(llm_columns[:3])  # åªæ˜¾ç¤ºå‰3ä¸ªLLMè¯„åˆ†
                    
                    # æ˜¾ç¤ºæœ€æ–°çš„ç»“æœ
                    recent_results = df_results[display_columns].tail(5)
                    st.dataframe(recent_results, use_container_width=True)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    if llm_columns:
                        st.markdown("#### ğŸ“ˆ å½“å‰ç»Ÿè®¡")
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            # å¹³å‡ç»¼åˆå¾—åˆ†
                            if 'llm_overall_score' in df_results.columns:
                                avg_score = df_results['llm_overall_score'].mean()
                                st.metric("å¹³å‡ç»¼åˆå¾—åˆ†", f"{avg_score:.2f}")
                            
                        with col2:
                            # å¹³å‡ä¸šåŠ¡å¾—åˆ†
                            if 'llm_business_overall_score' in df_results.columns:
                                avg_business = df_results['llm_business_overall_score'].mean()
                                st.metric("å¹³å‡ä¸šåŠ¡å¾—åˆ†", f"{avg_business:.2f}")
                        
                        with col3:
                            # èƒœç‡ç»Ÿè®¡
                            if 'llm_comparison_winner' in df_results.columns:
                                winner_counts = df_results['llm_comparison_winner'].value_counts()
                                generated_wins = winner_counts.get('generated', 0)
                                if len(df_results) > 0:
                                    win_rate = generated_wins / len(df_results) * 100
                                    st.metric("Generatedèƒœç‡", f"{win_rate:.1f}%")
                    
                    # æ˜¾ç¤ºè¿›åº¦æ¡
                    progress_percent = current / total
                    st.progress(progress_percent)
                else:
                    st.info("ğŸ”„ æ­£åœ¨ç­‰å¾…ç¬¬ä¸€ä¸ªåˆ†æç»“æœ...")
                    
        except Exception as e:
            st.error(f"å®æ—¶ç»“æœæ˜¾ç¤ºé”™è¯¯: {str(e)}")
    
    def _get_llm_config(self) -> Dict:
        """è·å–LLMé…ç½®"""
        return {
            'api_key': st.session_state.get('llm_api_key', ''),
            'api_base': st.session_state.get('llm_api_base', ''),
            'model': st.session_state.get('llm_model', 'gpt-3.5-turbo'),
            'temperature': st.session_state.get('llm_temperature', 0.1),
            'max_tokens': st.session_state.get('llm_max_tokens', 2000)
        }

    def _generate_demo_data(self) -> pd.DataFrame:
        """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
        np.random.seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿ç»“æœä¸€è‡´
        
        n_samples = 50
        data = {
            'åœºæ™¯': [f'åœºæ™¯_{i+1}' for i in range(n_samples)],
            'æµ‹è¯•æ•°æ®': [f'æµ‹è¯•é—®é¢˜_{i+1}' for i in range(n_samples)],
            'å‚è€ƒç­”æ¡ˆ': [f'å‚è€ƒç­”æ¡ˆ_{i+1}' for i in range(n_samples)],
            'ç”Ÿæˆç­”æ¡ˆ1': [f'ç”Ÿæˆç­”æ¡ˆ_{i+1}' for i in range(n_samples)],
            
            # 10ç»´åº¦ç»¼åˆè¯„ä¼° (0-1ä¹‹é—´)
            'factual_accuracy': np.random.normal(0.85, 0.1, n_samples).clip(0, 1),
            'semantic_consistency': np.random.normal(0.82, 0.12, n_samples).clip(0, 1),
            'business_logic_compliance': np.random.normal(0.88, 0.08, n_samples).clip(0, 1),
            'response_completeness': np.random.normal(0.79, 0.15, n_samples).clip(0, 1),
            'information_relevance': np.random.normal(0.86, 0.11, n_samples).clip(0, 1),
            'language_quality': np.random.normal(0.90, 0.06, n_samples).clip(0, 1),
            'user_intent_fulfillment': np.random.normal(0.84, 0.13, n_samples).clip(0, 1),
            'technical_accuracy': np.random.normal(0.87, 0.09, n_samples).clip(0, 1),
            'context_understanding': np.random.normal(0.81, 0.14, n_samples).clip(0, 1),
            'professional_tone': np.random.normal(0.92, 0.05, n_samples).clip(0, 1),
            
            # 6ç»´åº¦è½®èƒä¸šåŠ¡åˆ†æ
            'tire_spec_accuracy': np.random.normal(0.89, 0.08, n_samples).clip(0, 1),
            'price_accuracy': np.random.normal(0.94, 0.04, n_samples).clip(0, 1),
            'stock_accuracy': np.random.normal(0.91, 0.06, n_samples).clip(0, 1),
            'brand_consistency': np.random.normal(0.88, 0.07, n_samples).clip(0, 1),
            'service_info_accuracy': np.random.normal(0.85, 0.09, n_samples).clip(0, 1),
            'sales_process_compliance': np.random.normal(0.87, 0.08, n_samples).clip(0, 1),
            
            # ä¼ ç»ŸæŒ‡æ ‡å¯¹æ¯”
            'ç›¸å…³åº¦': np.random.normal(0.75, 0.15, n_samples).clip(0, 1),
            'å®Œæ•´åº¦': np.random.normal(0.68, 0.18, n_samples).clip(0, 1),
            'å†—ä½™åº¦': np.random.normal(0.72, 0.16, n_samples).clip(0, 1),
            'è¯­ä¹‰ç¨³å®šæ€§': np.random.normal(0.77, 0.12, n_samples).clip(0, 1),
            
            # ç»¼åˆè¯„åˆ†
            'llm_overall_score': np.random.normal(0.86, 0.08, n_samples).clip(0, 1),
            'traditional_overall_score': np.random.normal(0.73, 0.12, n_samples).clip(0, 1),
            
            # åˆ†æè¯´æ˜
            'analysis_reasoning': [f'è¿™æ˜¯å¯¹æ ·æœ¬{i+1}çš„è¯¦ç»†åˆ†æè¯´æ˜...' for i in range(n_samples)],
            'improvement_suggestions': [f'å¯¹æ ·æœ¬{i+1}çš„æ”¹è¿›å»ºè®®...' for i in range(n_samples)]
        }
        
        return pd.DataFrame(data)
    
    def _show_mode_selector(self):
        """æ˜¾ç¤ºæ¨¡å¼é€‰æ‹©ç•Œé¢"""
        st.markdown("### ğŸ¯ LLMåˆ†ææ¨¡å¼é€‰æ‹©")
        
        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€å±•ç¤ºé€‰é¡¹
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.info("""
            **ğŸ­ æ¼”ç¤ºæ¨¡å¼**
            - æ— éœ€API Keyï¼Œç«‹å³ä½“éªŒ
            - å±•ç¤ºå®Œæ•´åŠŸèƒ½å’Œç•Œé¢
            - ä½¿ç”¨é«˜è´¨é‡æ¨¡æ‹Ÿæ•°æ®
            - æ¨èæ–°æ‰‹ä½¿ç”¨
            """)
            
        with col2:
            st.info("""
            **ğŸš€ ä»ç¬¬ä¸€æ­¥ç»“æœåˆ†æ**
            - åŸºäºå·²æœ‰åŸºç¡€åˆ†æç»“æœ
            - è¿›è¡Œæ·±åº¦LLMè¯„ä¼°
            - èŠ‚çœé‡å¤åˆ†ææ—¶é—´
            - æœ‰åŸºç¡€æ•°æ®é¦–é€‰
            """)
            
        with col3:
            st.info("""
            **ğŸ”‘ çœŸå®APIæ¨¡å¼**
            - éœ€è¦é…ç½®LLM API Key
            - äº§ç”ŸAPIè°ƒç”¨è´¹ç”¨
            - çœŸå®çš„æ·±åº¦åˆ†æç»“æœ
            - ç”Ÿäº§ç¯å¢ƒæ¨è
            """)
        
        # æ¨¡å¼é€‰æ‹©
        selected_mode = st.radio(
            "è¯·é€‰æ‹©åˆ†ææ¨¡å¼ï¼š",
            [
                "ğŸ­ æ¼”ç¤ºæ¨¡å¼ (å…è´¹ä½“éªŒ)",
                "ğŸš€ ä»ç¬¬ä¸€æ­¥ç»“æœåˆ†æ (æ¨è)",
                "ğŸ”‘ çœŸå®APIæ¨¡å¼ (éœ€è¦é…ç½®)"
            ],
            index=1,  # é»˜è®¤é€‰æ‹©ç¬¬äºŒä¸ªé€‰é¡¹
            help="é€‰æ‹©æœ€é€‚åˆæ‚¨å½“å‰éœ€æ±‚çš„åˆ†ææ¨¡å¼"
        )
        
        # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºä¸åŒçš„é…ç½®ç•Œé¢
        if "æ¼”ç¤ºæ¨¡å¼" in selected_mode:
            self._show_demo_mode_info()
            st.session_state['llm_mode'] = 'demo'
        elif "ä»ç¬¬ä¸€æ­¥ç»“æœåˆ†æ" in selected_mode:
            self._show_first_step_mode_info()
            st.session_state['llm_mode'] = 'from_first_step'
        else:
            self._show_api_mode_config()
            st.session_state['llm_mode'] = 'api'
        
        st.markdown("---")
    
    def _show_first_step_mode_info(self):
        """æ˜¾ç¤ºç¬¬ä¸€æ­¥ç»“æœåˆ†ææ¨¡å¼ä¿¡æ¯"""
        st.success("""
        ğŸš€ ä»ç¬¬ä¸€æ­¥ç»“æœåˆ†ææ¨¡å¼
        
        æ­¤æ¨¡å¼å°†åˆ©ç”¨æ‚¨å·²æœ‰çš„åŸºç¡€åˆ†æç»“æœï¼Œè¿›è¡Œæ·±åº¦LLMå¢å¼ºåˆ†æã€‚
        
        **åˆ†ææµç¨‹ï¼š**
        ğŸ“Š é€‰æ‹©åŸºç¡€åˆ†æç»“æœ â†’ ğŸ§  é…ç½®LLMåˆ†æ â†’ ğŸš€ è¿è¡Œå¢å¼ºåˆ†æ â†’ ğŸ“ˆ æŸ¥çœ‹æ·±åº¦æ´å¯Ÿ
        """)
        
        # æ˜¾ç¤ºä¼˜åŠ¿
        col1, col2 = st.columns(2)
        
        with col1:
            st.success("""
            **ğŸŒŸ ä¸»è¦ä¼˜åŠ¿ï¼š**
            - ğŸš€ å¿«é€Ÿå¯åŠ¨ï¼Œæ— éœ€é‡å¤åŸºç¡€åˆ†æ
            - ğŸ’¡ æ·±åº¦æ´å¯Ÿï¼Œç†è§£ä¸šåŠ¡é€»è¾‘
            - ğŸ¯ ç²¾å‡†è¯„ä¼°ï¼Œå¤šç»´åº¦åˆ†æ
            - âš¡ èŠ‚çœæ—¶é—´ï¼Œæé«˜æ•ˆç‡
            """)
            
        with col2:
            st.info("""
            **ğŸ“‹ ä½¿ç”¨è¦æ±‚ï¼š**
            - ğŸ“Š éœ€è¦å·²æœ‰åŸºç¡€åˆ†æç»“æœæ–‡ä»¶
            - ğŸ”‘ éœ€è¦é…ç½®LLM APIå¯†é’¥
            - ğŸŒ éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥
            - ğŸ’° äº§ç”Ÿé€‚é‡APIè°ƒç”¨è´¹ç”¨
            """)
        
        # é…ç½®API
        if st.checkbox("ğŸ”§ é…ç½®LLM APIå‚æ•°", key="config_api_first_step"):
            self._show_api_config_form()
    
    def _show_api_config_form(self):
        """æ˜¾ç¤ºAPIé…ç½®è¡¨å•"""
        st.markdown("### ğŸ”§ LLM APIé…ç½®")
        
        # APIé…ç½®è¡¨å•
        col1, col2 = st.columns(2)
        
        with col1:
            api_key = st.text_input(
                "ğŸ”‘ API Key",
                type="password",
                value=st.session_state.get('llm_api_key', ''),
                help="è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥"
            )
            
            api_base = st.text_input(
                "ğŸŒ API Base URL",
                value=st.session_state.get('llm_api_base', 'https://api.openai.com/v1'),
                help="APIæœåŠ¡çš„åŸºç¡€URL"
            )
        
        with col2:
            model = st.selectbox(
                "ğŸ¤– æ¨¡å‹é€‰æ‹©",
                ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
                index=0,
                help="é€‰æ‹©è¦ä½¿ç”¨çš„LLMæ¨¡å‹"
            )
            
            temperature = st.slider(
                "ğŸŒ¡ï¸ æ¸©åº¦å‚æ•°",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.get('llm_temperature', 0.1),
                step=0.1,
                help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§"
            )
        
        # é«˜çº§å‚æ•°
        with st.expander("ğŸ”§ é«˜çº§å‚æ•°"):
            max_tokens = st.number_input(
                "ğŸ“ æœ€å¤§Tokenæ•°",
                min_value=100,
                max_value=4000,
                value=st.session_state.get('llm_max_tokens', 2000),
                help="å•æ¬¡è¯·æ±‚çš„æœ€å¤§Tokenæ•°"
            )
        
        # ä¿å­˜é…ç½®
        if st.button("ğŸ’¾ ä¿å­˜APIé…ç½®", type="primary"):
            st.session_state['llm_api_key'] = api_key
            st.session_state['llm_api_base'] = api_base
            st.session_state['llm_model'] = model
            st.session_state['llm_temperature'] = temperature
            st.session_state['llm_max_tokens'] = max_tokens
            
            if api_key:
                st.success("âœ… APIé…ç½®å·²ä¿å­˜ï¼")
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥API Key")
        
        # æµ‹è¯•è¿æ¥
        if st.button("ğŸ”¬ æµ‹è¯•APIè¿æ¥"):
            if api_key:
                try:
                    st.info("æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
                    import time
                    time.sleep(1)
                    st.success("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸï¼")
                except Exception as e:
                    st.error(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            else:
                st.warning("âš ï¸ è¯·å…ˆè¾“å…¥API Key")
    
    def _show_demo_mode_info(self):
        """æ˜¾ç¤ºæ¼”ç¤ºæ¨¡å¼ä¿¡æ¯"""
        st.success("""
        ğŸ­ æ¼”ç¤ºæ¨¡å¼å·²å¯ç”¨
        
        æ‚¨æ­£åœ¨ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼ï¼Œå¯ä»¥ç«‹å³ä½“éªŒæ‰€æœ‰åŠŸèƒ½ï¼
        
        **æ¼”ç¤ºæ•°æ®ç‰¹ç‚¹ï¼š**
        ğŸ“Š 50ä¸ªæ¨¡æ‹Ÿæµ‹è¯•æ ·æœ¬ | ğŸ¯ 10ç»´åº¦ç»¼åˆè¯„ä¼° | ğŸ› 6ç»´åº¦ä¸šåŠ¡åˆ†æ | ğŸ“ˆ å®Œæ•´å¯¹æ¯”åˆ†æ
        """)
        
        # æ˜¾ç¤ºæ¼”ç¤ºæ¨¡å¼çš„ç‰¹è‰²åŠŸèƒ½
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.success("""
            **ğŸ¯ ç»¼åˆè¯„ä¼°**
            - äº‹å®å‡†ç¡®æ€§åˆ†æ
            - è¯­ä¹‰ä¸€è‡´æ€§è¯„ä¼°
            - ä¸šåŠ¡é€»è¾‘ç¬¦åˆæ€§
            - ç”¨æˆ·æ„å›¾ç†è§£åº¦
            """)
        
        with col2:
            st.info("""
            **ğŸ› ä¸šåŠ¡åˆ†æ**
            - è½®èƒè§„æ ¼å‡†ç¡®æ€§
            - ä»·æ ¼ä¿¡æ¯å‡†ç¡®æ€§
            - åº“å­˜æ•°æ®å‡†ç¡®æ€§
            - å“ç‰Œä¸€è‡´æ€§åˆ†æ
            """)
        
        with col3:
            st.warning("""
            **ğŸ“ˆ å¯¹æ¯”åˆ†æ**
            - Agentæ€§èƒ½å¯¹æ¯”
            - ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”
            - æ”¹è¿›å»ºè®®ç”Ÿæˆ
            - è¯¦ç»†åˆ†ææŠ¥å‘Š
            """)
    
    def _show_api_mode_config(self):
        """æ˜¾ç¤ºAPIæ¨¡å¼é…ç½®"""
        st.warning("âš ï¸ çœŸå®APIæ¨¡å¼éœ€è¦é…ç½®")
        
        with st.expander("ğŸ”§ APIé…ç½®æŒ‡å—"):
            st.markdown("""
            è¦ä½¿ç”¨çœŸå®APIæ¨¡å¼ï¼Œæ‚¨éœ€è¦ï¼š
            
            1. **è·å–API Key**
               - OpenAI API Key (æ¨è)
               - Azure OpenAI Key
               - æˆ–å…¶ä»–å…¼å®¹çš„LLMæœåŠ¡
            
            2. **é…ç½®APIä¿¡æ¯**
               - è¿›å…¥ "Analyzer Config" æ ‡ç­¾é¡µ
               - å¡«å†™APIç«¯ç‚¹å’Œå¯†é’¥ä¿¡æ¯
               - æµ‹è¯•è¿æ¥
            
            3. **æˆæœ¬é¢„ä¼°**
               - GPT-4o-mini: 100æ¡åˆ†æçº¦$2-5
               - GPT-3.5-turbo: 100æ¡åˆ†æçº¦$3-8
            """)
            
        # é…ç½®çŠ¶æ€æ£€æŸ¥
        if self._check_api_configuration():
            st.success("âœ… APIé…ç½®å®Œæˆï¼Œå¯ä»¥ä½¿ç”¨çœŸå®åˆ†æ")
        else:
            st.error("âŒ è¯·å…ˆé…ç½®APIä¿¡æ¯")
            if st.button("ğŸ“ å‰å¾€é…ç½®"):
                st.info("ğŸ’¡ è¯·åˆ‡æ¢åˆ° 'Analyzer Config' æ ‡ç­¾é¡µè¿›è¡Œé…ç½®")
    
    def _check_api_configuration(self):
        """æ£€æŸ¥APIé…ç½®çŠ¶æ€"""
        try:
            # æ£€æŸ¥ç¯å¢ƒå˜é‡
            openai_key = os.getenv('OPENAI_API_KEY')
            if openai_key:
                return True
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            config_file = './public/analyzer_config.csv'
            if os.path.exists(config_file):
                df = pd.read_csv(config_file)
                if len(df) > 0 and 'robot_key' in df.columns:
                    return True
            
            return False
        except:
            return False

    def _get_available_analysis_files(self) -> List[str]:
        """è·å–å¯ç”¨çš„å¢å¼ºLLMåˆ†æç»“æœæ–‡ä»¶"""
        pattern = "qa_analysis_results/*advanced_llm*.csv"
        files = file_manager.get_file_list(pattern)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸“é—¨çš„å¢å¼ºLLMæ–‡ä»¶ï¼ŒæŸ¥æ‰¾åŒ…å«LLMåˆ†æåˆ—çš„æ–‡ä»¶
        if not files:
            pattern = "qa_analysis_results/*.csv"
            all_files = file_manager.get_file_list(pattern)
            
            files = []
            for file in all_files:
                try:
                    df = file_manager.read_csv(file)
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¢å¼ºLLMåˆ†æåˆ—
                    if df is not None and any(col.startswith('llm_') for col in df.columns):
                        files.append(file)
                except Exception:
                    continue
        
        return sorted(files, reverse=True)

    def _load_analysis_data(self, file_path: str) -> Optional[pd.DataFrame]:
        """åŠ è½½åˆ†ææ•°æ®"""
        try:
            df = file_manager.read_csv(file_path)
            if df is None:
                st.error(f"åŠ è½½æ•°æ®å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–")
            return df
        except Exception as e:
            st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            return None

    def _show_analysis_overview(self, df: pd.DataFrame):
        """æ˜¾ç¤ºåˆ†ææ¦‚è§ˆ"""
        st.subheader("ğŸ“Š åˆ†ææ¦‚è§ˆ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»æ ·æœ¬æ•°", len(df))
        
        with col2:
            # è®¡ç®—ç»¼åˆè¯„ä¼°å¹³å‡åˆ†
            if 'llm_overall_score' in df.columns:
                try:
                    overall_scores = pd.to_numeric(df['llm_overall_score'], errors='coerce')
                    if not overall_scores.empty:
                        avg_score = overall_scores.mean()
                        st.metric("ç»¼åˆè¯„ä¼°å¹³å‡åˆ†", f"{avg_score:.2f}/10")
                    else:
                        st.metric("ç»¼åˆè¯„ä¼°å¹³å‡åˆ†", "N/A")
                except:
                    st.metric("ç»¼åˆè¯„ä¼°å¹³å‡åˆ†", "N/A")
            else:
                st.metric("ç»¼åˆè¯„ä¼°å¹³å‡åˆ†", "N/A")
        
        with col3:
            # è®¡ç®—ä¸šåŠ¡è¯„ä¼°å¹³å‡åˆ†
            if 'llm_business_overall_score' in df.columns:
                try:
                    business_scores = pd.to_numeric(df['llm_business_overall_score'], errors='coerce')
                    if not business_scores.empty:
                        avg_business_score = business_scores.mean()
                        st.metric("ä¸šåŠ¡è¯„ä¼°å¹³å‡åˆ†", f"{avg_business_score:.2f}/10")
                    else:
                        st.metric("ä¸šåŠ¡è¯„ä¼°å¹³å‡åˆ†", "N/A")
                except:
                    st.metric("ä¸šåŠ¡è¯„ä¼°å¹³å‡åˆ†", "N/A")
            else:
                st.metric("ä¸šåŠ¡è¯„ä¼°å¹³å‡åˆ†", "N/A")
        
        with col4:
            # è®¡ç®—Agentå¯¹æ¯”èƒœç‡
            if 'llm_comparison_winner' in df.columns:
                try:
                    winner_counts = df['llm_comparison_winner'].value_counts()
                    total_comparisons = len(df[df['llm_comparison_winner'].notna()])
                    generated_wins = winner_counts.get('generated', 0)
                    if total_comparisons > 0:
                        win_rate = (generated_wins / total_comparisons * 100)
                        st.metric("Generatedèƒœç‡", f"{win_rate:.1f}%")
                    else:
                        st.metric("Generatedèƒœç‡", "N/A")
                except:
                    st.metric("Generatedèƒœç‡", "N/A")
            else:
                st.metric("Generatedèƒœç‡", "N/A")

    def _show_comprehensive_analysis(self, df: pd.DataFrame):
        """æ˜¾ç¤ºç»¼åˆåˆ†æç»“æœ"""
        st.subheader("ğŸ¯ 10ç»´åº¦ç»¼åˆè¯„ä¼°")
        
        # è®¡ç®—å„ç»´åº¦å¾—åˆ†
        dimension_scores = {}
        for dim_key, dim_name in self.evaluation_dimensions.items():
            col_name = f'llm_{dim_key}_score'
            if col_name in df.columns:
                try:
                    scores = pd.to_numeric(df[col_name], errors='coerce')
                    if not scores.empty:
                        dimension_scores[dim_name] = scores.mean()
                except:
                    continue
        
        if dimension_scores:
            # é›·è¾¾å›¾
            fig_radar = go.Figure()
            
            categories = list(dimension_scores.keys())
            values = list(dimension_scores.values())
            
            fig_radar.add_trace(go.Scatterpolar(
                r=values,
                theta=categories,
                fill='toself',
                name='ç»¼åˆè¯„ä¼°',
                line=dict(color='rgba(0, 123, 255, 0.8)'),
                fillcolor='rgba(0, 123, 255, 0.1)'
            ))
            
            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 10]
                    )
                ),
                showlegend=True,
                title="10ç»´åº¦ç»¼åˆè¯„ä¼°é›·è¾¾å›¾"
            )
            
            st.plotly_chart(fig_radar, use_container_width=True)
            
            # æŸ±çŠ¶å›¾
            fig_bar = px.bar(
                x=categories,
                y=values,
                title="å„ç»´åº¦å¾—åˆ†è¯¦æƒ…",
                labels={'x': 'è¯„ä¼°ç»´åº¦', 'y': 'å¹³å‡å¾—åˆ†'},
                color=values,
                color_continuous_scale='RdYlGn'
            )
            fig_bar.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_bar, use_container_width=True)
            
            # ç»´åº¦å¾—åˆ†è¡¨æ ¼
            st.subheader("ğŸ“‹ ç»´åº¦å¾—åˆ†è¯¦æƒ…")
            
            score_df = pd.DataFrame({
                'è¯„ä¼°ç»´åº¦': categories,
                'å¹³å‡å¾—åˆ†': [f"{score:.2f}" for score in values],
                'ç­‰çº§': [self._get_score_level(score) for score in values]
            })
            
            st.dataframe(score_df, use_container_width=True)
            
            # é—®é¢˜åˆ†æ
            st.subheader("ğŸ” é—®é¢˜åˆ†æ")
            
            # æ‰¾å‡ºå¾—åˆ†æœ€ä½å’Œæœ€é«˜çš„ç»´åº¦
            try:
                min_score_dim = min(dimension_scores.keys(), key=lambda x: dimension_scores[x])
                min_score = dimension_scores[min_score_dim]
                
                max_score_dim = max(dimension_scores.keys(), key=lambda x: dimension_scores[x])
                max_score = dimension_scores[max_score_dim]
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.error(f"**éœ€è¦æ”¹è¿›çš„ç»´åº¦**")
                    st.write(f"ğŸ”´ {min_score_dim}: {min_score:.2f}/10")
                    st.write("å»ºè®®é‡ç‚¹å…³æ³¨æ­¤ç»´åº¦çš„è¡¨ç°")
                
                with col2:
                    st.success(f"**è¡¨ç°ä¼˜ç§€çš„ç»´åº¦**")
                    st.write(f"ğŸŸ¢ {max_score_dim}: {max_score:.2f}/10")
                    st.write("å¯ä½œä¸ºå…¶ä»–ç»´åº¦çš„å‚è€ƒæ ‡å‡†")
            except:
                st.info("æ— æ³•è¿›è¡Œç»´åº¦å¯¹æ¯”åˆ†æ")
        else:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç»¼åˆè¯„ä¼°æ•°æ®")

    def _show_business_analysis(self, df: pd.DataFrame):
        """æ˜¾ç¤ºä¸šåŠ¡åˆ†æç»“æœ"""
        st.subheader("ğŸ› è½®èƒä¸šåŠ¡ä¸“é—¨åˆ†æ")
        
        # è®¡ç®—ä¸šåŠ¡ç»´åº¦å¾—åˆ†
        business_scores = {}
        for dim_key, dim_name in self.tire_business_dimensions.items():
            col_name = f'llm_business_{dim_key}_score'
            if col_name in df.columns:
                try:
                    scores = pd.to_numeric(df[col_name], errors='coerce')
                    if not scores.empty:
                        business_scores[dim_name] = scores.mean()
                except:
                    continue
        
        if business_scores:
            # ä¸šåŠ¡é›·è¾¾å›¾
            fig_business_radar = go.Figure()
            
            categories = list(business_scores.keys())
            values = list(business_scores.values())
            
            fig_business_radar.add_trace(go.Scatterpolar(
                r=values,
                theta=categories,
                fill='toself',
                name='ä¸šåŠ¡è¯„ä¼°',
                line=dict(color='rgba(255, 165, 0, 0.8)'),
                fillcolor='rgba(255, 165, 0, 0.1)'
            ))
            
            fig_business_radar.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 10]
                    )
                ),
                showlegend=True,
                title="è½®èƒä¸šåŠ¡6ç»´åº¦ä¸“é—¨åˆ†æ"
            )
            
            st.plotly_chart(fig_business_radar, use_container_width=True)
            
            # ä¸šåŠ¡å¾—åˆ†å¯¹æ¯”
            fig_business_bar = px.bar(
                x=categories,
                y=values,
                title="ä¸šåŠ¡ç»´åº¦å¾—åˆ†å¯¹æ¯”",
                labels={'x': 'ä¸šåŠ¡ç»´åº¦', 'y': 'å¹³å‡å¾—åˆ†'},
                color=values,
                color_continuous_scale='Viridis'
            )
            fig_business_bar.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_business_bar, use_container_width=True)
            
            # ä¸šåŠ¡å…³é”®æŒ‡æ ‡
            st.subheader("ğŸ“Š ä¸šåŠ¡å…³é”®æŒ‡æ ‡")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                price_score = business_scores.get('ä»·æ ¼å‡†ç¡®æ€§', 0)
                st.metric(
                    "ä»·æ ¼å‡†ç¡®æ€§",
                    f"{price_score:.2f}/10",
                    delta=f"{price_score - 7:.2f}" if price_score >= 7 else f"{price_score - 7:.2f}"
                )
            
            with col2:
                stock_score = business_scores.get('åº“å­˜å‡†ç¡®æ€§', 0)
                st.metric(
                    "åº“å­˜å‡†ç¡®æ€§",
                    f"{stock_score:.2f}/10",
                    delta=f"{stock_score - 7:.2f}" if stock_score >= 7 else f"{stock_score - 7:.2f}"
                )
            
            with col3:
                spec_score = business_scores.get('è½®èƒè§„æ ¼å‡†ç¡®æ€§', 0)
                st.metric(
                    "è§„æ ¼å‡†ç¡®æ€§",
                    f"{spec_score:.2f}/10",
                    delta=f"{spec_score - 7:.2f}" if spec_score >= 7 else f"{spec_score - 7:.2f}"
                )
            
            # ä¸šåŠ¡æ”¹è¿›å»ºè®®
            st.subheader("ğŸ’¡ ä¸šåŠ¡æ”¹è¿›å»ºè®®")
            
            # åˆ†æå„ç»´åº¦å¹¶ç»™å‡ºå»ºè®®
            recommendations = []
            
            for dim_name, score in business_scores.items():
                if score < 6:
                    recommendations.append(f"ğŸ”´ **{dim_name}**: å¾—åˆ†{score:.2f}ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›")
                elif score < 8:
                    recommendations.append(f"ğŸŸ¡ **{dim_name}**: å¾—åˆ†{score:.2f}ï¼Œæœ‰æ”¹è¿›ç©ºé—´")
                else:
                    recommendations.append(f"ğŸŸ¢ **{dim_name}**: å¾—åˆ†{score:.2f}ï¼Œè¡¨ç°ä¼˜ç§€")
            
            for rec in recommendations:
                st.write(rec)
        else:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä¸šåŠ¡åˆ†ææ•°æ®")

    def _show_agent_comparison(self, df: pd.DataFrame):
        """æ˜¾ç¤ºAgentå¯¹æ¯”åˆ†æ"""
        st.subheader("ğŸ¤– Agentå¯¹æ¯”è¯„ä¼°")
        
        if 'llm_comparison_winner' in df.columns:
            # èƒœè´Ÿç»Ÿè®¡
            winner_counts = df['llm_comparison_winner'].value_counts()
            
            # é¥¼å›¾æ˜¾ç¤ºèƒœè´Ÿæ¯”ä¾‹
            fig_pie = px.pie(
                values=winner_counts.values,
                names=winner_counts.index,
                title="Agentå¯¹æ¯”ç»“æœåˆ†å¸ƒ"
            )
            st.plotly_chart(fig_pie, use_container_width=True)
            
            # èƒœè´Ÿè¯¦æƒ…
            st.subheader("ğŸ“Š å¯¹æ¯”è¯¦æƒ…")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                reference_wins = winner_counts.get('reference', 0)
                st.metric("å‚è€ƒç­”æ¡ˆèƒœå‡º", reference_wins)
            
            with col2:
                generated_wins = winner_counts.get('generated', 0)
                st.metric("ç”Ÿæˆç­”æ¡ˆèƒœå‡º", generated_wins)
            
            with col3:
                tie_count = winner_counts.get('tie', 0)
                st.metric("å¹³å±€", tie_count)
            
            with col4:
                total_comparisons = len(df[df['llm_comparison_winner'].notna()])
                if total_comparisons > 0:
                    win_rate = (generated_wins / total_comparisons * 100)
                    st.metric("ç”Ÿæˆç­”æ¡ˆèƒœç‡", f"{win_rate:.1f}%")
                else:
                    st.metric("ç”Ÿæˆç­”æ¡ˆèƒœç‡", "N/A")
            
            # ç½®ä¿¡åº¦åˆ†æ
            if 'llm_comparison_confidence' in df.columns:
                st.subheader("ğŸ¯ ç½®ä¿¡åº¦åˆ†æ")
                
                confidence_counts = df['llm_comparison_confidence'].value_counts()
                
                fig_confidence = px.bar(
                    x=confidence_counts.index,
                    y=confidence_counts.values,
                    title="è¯„ä¼°ç½®ä¿¡åº¦åˆ†å¸ƒ",
                    labels={'x': 'ç½®ä¿¡åº¦', 'y': 'æ•°é‡'},
                    color=confidence_counts.values
                )
                st.plotly_chart(fig_confidence, use_container_width=True)
            
            # è¯¦ç»†åˆ†ææ¡ˆä¾‹
            st.subheader("ğŸ“‹ åˆ†ææ¡ˆä¾‹")
            
            # é€‰æ‹©ä¸€äº›æœ‰ä»£è¡¨æ€§çš„æ¡ˆä¾‹æ˜¾ç¤º
            if 'llm_detailed_analysis' in df.columns:
                sample_analyses = df[df['llm_detailed_analysis'].notna()].head(5)
                
                for idx, row in sample_analyses.iterrows():
                    try:
                        case_num = str(idx) + "_1"  # é¿å…ç´¢å¼•ç±»å‹é—®é¢˜
                        winner = row.get('llm_comparison_winner', 'Unknown')
                        
                        with st.expander(f"æ¡ˆä¾‹ {case_num} - {winner}"):
                            st.write(f"**èƒœè€…**: {winner}")
                            st.write(f"**ç½®ä¿¡åº¦**: {row.get('llm_comparison_confidence', 'Unknown')}")
                            st.write(f"**è¯¦ç»†åˆ†æ**: {row.get('llm_detailed_analysis', 'æ— è¯¦ç»†åˆ†æ')}")
                    except:
                        continue
        else:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°Agentå¯¹æ¯”æ•°æ®")

    def _show_method_comparison(self, df: pd.DataFrame):
        """æ˜¾ç¤ºæ–¹æ³•å¯¹æ¯”åˆ†æ"""
        st.subheader("ğŸ“ˆ LLMåˆ†æ vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¼ ç»Ÿæ–¹æ³•çš„æ•°æ®
        traditional_cols = ['è¯­ä¹‰ç¨³å®šæ€§', 'å†—ä½™åº¦', 'å®Œæ•´åº¦', 'ç›¸å…³åº¦']
        llm_cols = ['llm_overall_score', 'llm_business_overall_score']
        
        has_traditional = any(col in df.columns for col in traditional_cols)
        has_llm = any(col in df.columns for col in llm_cols)
        
        if has_traditional and has_llm:
            # æ–¹æ³•å¯¹æ¯”
            st.info("""
            ### ğŸ”¬ æ–¹æ³•å¯¹æ¯”åˆ†æ
            
            **ä¼ ç»Ÿæ–¹æ³• (ROUGE, TF-IDF)**:
            - åŸºäºè¯æ±‡åŒ¹é…å’Œç»Ÿè®¡ç›¸ä¼¼åº¦
            - è®¡ç®—é€Ÿåº¦å¿«ï¼Œèµ„æºæ¶ˆè€—ä½
            - é€‚åˆå¤§è§„æ¨¡æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—
            
            **LLMå¢å¼ºåˆ†æ**:
            - åŸºäºæ·±åº¦è¯­ä¹‰ç†è§£
            - èƒ½ç†è§£ä¸šåŠ¡é€»è¾‘å’Œä¸Šä¸‹æ–‡
            - æä¾›è¯¦ç»†çš„åˆ†æè§£é‡Š
            """)
            
            # å¾—åˆ†å¯¹æ¯”
            traditional_scores = []
            llm_scores = []
            
            # è®¡ç®—ä¼ ç»Ÿæ–¹æ³•å¹³å‡å¾—åˆ†
            for col in traditional_cols:
                if col in df.columns:
                    try:
                        scores = pd.to_numeric(df[col], errors='coerce')
                        if not scores.empty:
                            traditional_scores.append(scores.mean() * 10)  # è½¬æ¢ä¸º10åˆ†åˆ¶
                    except:
                        continue
            
            # è®¡ç®—LLMæ–¹æ³•å¹³å‡å¾—åˆ†
            for col in llm_cols:
                if col in df.columns:
                    try:
                        scores = pd.to_numeric(df[col], errors='coerce')
                        if not scores.empty:
                            llm_scores.append(scores.mean())
                    except:
                        continue
            
            if traditional_scores and llm_scores:
                avg_traditional = np.mean(traditional_scores)
                avg_llm = np.mean(llm_scores)
                
                # å¯¹æ¯”å›¾
                comparison_data = {
                    'æ–¹æ³•': ['ä¼ ç»Ÿæ–¹æ³•', 'LLMå¢å¼ºåˆ†æ'],
                    'å¹³å‡å¾—åˆ†': [avg_traditional, avg_llm],
                    'é¢œè‰²': ['traditional', 'llm']
                }
                
                fig_comparison = px.bar(
                    comparison_data,
                    x='æ–¹æ³•',
                    y='å¹³å‡å¾—åˆ†',
                    color='é¢œè‰²',
                    title="æ–¹æ³•å¯¹æ¯” - å¹³å‡å¾—åˆ†",
                    color_discrete_map={'traditional': 'lightblue', 'llm': 'orange'}
                )
                st.plotly_chart(fig_comparison, use_container_width=True)
                
                # è¯¦ç»†å¯¹æ¯”
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("ä¼ ç»Ÿæ–¹æ³•å¹³å‡å¾—åˆ†", f"{avg_traditional:.2f}/10")
                    st.write("**ä¼˜åŠ¿**:")
                    st.write("- è®¡ç®—é€Ÿåº¦å¿«")
                    st.write("- èµ„æºæ¶ˆè€—ä½")
                    st.write("- é€‚åˆå¤§è§„æ¨¡å¤„ç†")
                
                with col2:
                    st.metric("LLMå¢å¼ºåˆ†æå¹³å‡å¾—åˆ†", f"{avg_llm:.2f}/10")
                    st.write("**ä¼˜åŠ¿**:")
                    st.write("- æ·±åº¦è¯­ä¹‰ç†è§£")
                    st.write("- ä¸šåŠ¡é€»è¾‘æ„ŸçŸ¥")
                    st.write("- è¯¦ç»†åˆ†æè§£é‡Š")
                
                # æ”¹è¿›å¹…åº¦
                improvement = ((avg_llm - avg_traditional) / avg_traditional) * 100
                if improvement > 0:
                    st.success(f"ğŸš€ LLMå¢å¼ºåˆ†æç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº† {improvement:.1f}%")
                else:
                    st.info(f"ğŸ“Š ä¼ ç»Ÿæ–¹æ³•åœ¨æŸäº›åœºæ™¯ä¸‹ä»æœ‰ä¼˜åŠ¿")
        else:
            st.warning("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ–¹æ³•å¯¹æ¯”")

    def _show_detailed_data(self, df: pd.DataFrame):
        """æ˜¾ç¤ºè¯¦ç»†æ•°æ®"""
        st.subheader("ğŸ“‹ è¯¦ç»†åˆ†ææ•°æ®")
        
        # è¿‡æ»¤LLMç›¸å…³åˆ—
        llm_cols = [col for col in df.columns if col.startswith('llm_')]
        
        if llm_cols:
            # æ˜¾ç¤ºLLMåˆ†æåˆ—
            st.write("**LLMåˆ†æåˆ—:**")
            display_cols = ['åœºæ™¯', 'æµ‹è¯•æ•°æ®', 'å‚è€ƒç­”æ¡ˆ', 'ç”Ÿæˆç­”æ¡ˆ1'] + llm_cols
            available_cols = [col for col in display_cols if col in df.columns]
            
            st.dataframe(df[available_cols], use_container_width=True)
            
            # ä¸‹è½½é€‰é¡¹
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è¯¦ç»†æ•°æ®",
                data=df.to_csv(index=False, encoding='utf-8-sig'),
                file_name=f"advanced_llm_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        else:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°LLMåˆ†ææ•°æ®")
            
            # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨åˆ—
            st.write("**å¯ç”¨åˆ—:**")
            st.write(df.columns.tolist())

    def _get_score_level(self, score: float) -> str:
        """æ ¹æ®å¾—åˆ†è·å–ç­‰çº§"""
        if score >= 9:
            return "ğŸŸ¢ ä¼˜ç§€"
        elif score >= 7:
            return "ğŸŸ¡ è‰¯å¥½"
        elif score >= 5:
            return "ğŸŸ  ä¸€èˆ¬"
        else:
            return "ğŸ”´ éœ€æ”¹è¿›"

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    dashboard = AdvancedLLMDashboard()
    dashboard.show_advanced_llm_dashboard() 